{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WIP 3D SIM reconstruction template\n",
    "\n",
    "This is a work in progress template for running 3D SIM reconstruction based on the Janelia Python and c SIM code written by David Hoffman and Lin Shao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.  Define code paths\n",
    "Currently we hard code these and they need to be modified to run on different machines.  In the future we may move to a more intelligent approach like always having code exist beside the notebooks and using relative imports.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pylab inline\n",
    "\n",
    "import tifffile as tif\n",
    "import os\n",
    "import glob\n",
    "%load_ext autoreload\n",
    "%autoreload \n",
    "import shutil\n",
    "\n",
    "# NOTE: BN the below code is from the legacy notebooks.  I am leaving it here for now, as it may be needed on some machines. \n",
    "if 'C:\\\\Users\\\\Cryo SIM-PALM\\\\Documents\\\\GitHub' in sys.path:\n",
    "    sys.path.remove('C:\\\\Users\\\\Cryo SIM-PALM\\\\Documents\\\\GitHub')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "computer = 'bnort'\n",
    "\n",
    "import sys\n",
    "\n",
    "if computer == 'default':\n",
    "    sys.path.insert(1, 'Y:\\Cryo_data2\\Data Processing Notebooks')\n",
    "    sys.path.insert(1, 'Y:\\Cryo_data2\\Data Processing Notebooks\\Scripts')\n",
    "elif computer == 'bnort':\n",
    "    sys.path.insert(1, r'C:\\Users\\bnort\\work\\Janelia\\code\\\\simrecon\\scripts\\Scripts')\n",
    "    sys.path.insert(1, r'C:\\Users\\bnort\\work\\Janelia\\code\\\\simrecon\\scripts')\n",
    "else:\n",
    "    pass\n",
    "\n",
    "import dphutils \n",
    "from simrecon_utils import simrecon, split_process_recombine\n",
    "\n",
    "# import dask\n",
    "import dask\n",
    "from dask.diagnostics import ProgressBar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup home directory and OTF directory:\n",
    "\n",
    "Right now we leave in paths for the current test machines but in the future may move to a more intelligent approach (for example user chooses paths with dialog box, paths stored in configuration)\n",
    "\n",
    "Home should start from {Hesslab(\\\\prfs.hhmi.org)} e.g. home = r'Y:\\Cryo_data2\\ORCA_data\\3D SIM Cells'\n",
    "\n",
    "#### Additonal legacy notes (BN: these notes were in the original notebook I got) I'm leaving them in for now in case we need them for troubleshhoting\n",
    "\n",
    "There was an old note \"OTF folder should be placed inside Data processing notebooks\"\n",
    "\n",
    "(BN I don't think this has to be the case, because there are many notebook that define the full OTF path)\n",
    "\n",
    "OTF Folder directory should be e.g.:   Y:\\Cryo_data2\\Data Processing Notebooks\\SIM PSFs OTFs\n",
    "\n",
    "Raw data from V-SIM data acquisition should be placed inside a dated folder here:   'Y:\\Cryo_data2\\ORCA_data\\3D SIM Cells' \n",
    "\n",
    "with data file directory structure e.g.: 'Y:\\Cryo_data2\\ORCA_data\\3D SIM Cells\\20240322\\488 nm 5 phases 0.81 NA Linear SIM_cam1_0.mrc'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if computer == 'default': \n",
    "    home = r'Y:\\Cryo_data2\\488nm comparison TILED VS Non-Tiled at different base kwarg settings'\n",
    "    otf_path = r'Y:\\Seyforth\\Data For Brian\\Cryo-SIM Scope #2 Data (James System)\\PSFs (best PSFs and examples of bad ones)\\BEAD 2 - NON-AR 1.2W 25ms retake_20240503_170242 BEST PSF!!\\computed_OTF_folder'\n",
    "elif computer == 'bnort':\n",
    "    #home = r'D:\\Janelia\\Data 2024-06-06\\Wiener, gammaApo and SupressR parameter testing\\488nm comparison Brian'\n",
    "    #home = r'D:\\Janelia\\Data 2024-10-02\\560cm cell 4 _20240627_124604'\n",
    "    home = r'D:\\Janelia\\Data 2024-10-10' \n",
    "    \n",
    "    #otf_path = r'D:\\Janelia\\Data 2024-06-06\\Wiener, gammaApo and SupressR parameter testing\\OTF\\BEAD 2 - NON-AR 1.2W 25ms retake_20240503_170242 BEST PSF!!\\computed_OTF_folder'\n",
    "    #otf_path = r'D:\\Janelia\\Data 2024-06-03\\PSF-OTF used (Davids set of 4 wavelengths)\\201909_19-20_best'\n",
    "    #otf_path = r'C:\\Users\\bnort\\work\\Janelia\\ims\\OTF_folder'\n",
    "OTFpath = os.path.join(otf_path,\"*{}*.mrc\")\n",
    "OTFs = {wl : [path for path in glob.iglob(OTFpath.format(wl))] for wl in (560, 532, 488, 642)}\n",
    "OTFs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set default params\n",
    "\n",
    "Here we set the default params that will be used if none of them are overwritten.\n",
    "\n",
    "Note that before calling the non-tiled and/or tiled processing code a small subset of parameters will be overwritten to values optimized for non-tiled/tiled processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# David Solecki's suggestion: wiener=0.007 gammaApo=0.7 and suppressR=15\n",
    "# original values by D.Hoffman: wiener=0.001 gammaApo=0.1 and suppressR=1.5\n",
    "\n",
    "base_kwargs = dict(\n",
    "                    nphases=5,\n",
    "                    ndirs=3,\n",
    "                    angle0= 1.36,\n",
    "                    negDangle=True,              # James made False to try experiment\n",
    "                    na= 0.85,\n",
    "                    nimm= 1.0,\n",
    "                    zoomfact= 2.0, \n",
    "                    background= 100.0,           # james experiment was 100.0\n",
    "                    wiener= 0.007,\n",
    "                    fastSIM=True,\n",
    "                    otfRA= True,\n",
    "                    dampenOrder0=True,\n",
    "                    k0searchall=True,\n",
    "                    equalizez=True,\n",
    "                    preciseapo=True,\n",
    "                    gammaApo=0.7,\n",
    "                    suppressR=15.0\n",
    "                )\n",
    "\n",
    "def return_wl_otfs(path):\n",
    "    if \"488 Exc 532 Em\" in path:\n",
    "        wl = 532\n",
    "    elif \"488 Exc 642 Em\" in path:\n",
    "        wl = 642\n",
    "    elif \"532 Exc 561 Em\" in path:\n",
    "        wl = 561\n",
    "    elif \"560 nm\" in path:\n",
    "        wl = 560\n",
    "    elif \"488 nm\" in path:\n",
    "        wl = 488\n",
    "    elif \"532 nm\" in path:\n",
    "        wl = 532\n",
    "    elif \"642 nm\" in path:\n",
    "        wl = 642\n",
    "\n",
    "    else:\n",
    "        raise RuntimeError(\"no matching filename wavelength found, fix directory or filename or code\")\n",
    "    return wl, OTFs[wl]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove old processed data\n",
    "\n",
    "This is commented out, but I assume we comment back in if we want to erase the previous run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''python\n",
    "# clear processed\n",
    "for path in glob.glob(home + \"/*/*proc *.mrc\"):\n",
    "    os.remove(path)\n",
    "for path in glob.glob(home + \"/*/*proc *.txt\"):\n",
    "    os.remove(path)\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define process function defined to use DASK and simrecon package\n",
    "\n",
    "This function is annotated as a dask ```delayed``` function.  Which means it will not be called right away but put in a queue to call using dask. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dask.delayed\n",
    "def process(sim_kwargs, output_file_name):\n",
    "    sim_output = simrecon(**sim_kwargs)\n",
    "    with open(output_file_name.replace(\".mrc\", \".txt\"), \"w\") as myfile:\n",
    "        myfile.write(str(sim_kwargs))\n",
    "        myfile.write(\"\\n\".join(sim_output))\n",
    "    return output_file_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell below checks for raw data which has already been processed using full frame SIM reconstruction algorithm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "done_already = set(glob.iglob(home + \"/**/*proc*.mrc\", recursive = True))\n",
    "done_already;\n",
    "done_already = set()     # do this if want to re-process\n",
    "print('Data processed already: \\n')\n",
    "\n",
    "for i in done_already:\n",
    "    print(i + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set up parameters common between Non-tiled and tiled reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "gammaApo = 0.3\n",
    "suppressR = 1\n",
    "wiener = 0.0001 \n",
    "\n",
    "user_text = 'gApo_'+str(gammaApo)+'_supR_'+str(suppressR)+'_w_'+str(wiener) \n",
    "\n",
    "nofilteroverlaps = False \n",
    "forcemodamp = False\n",
    "forceotfamp = False\n",
    "\n",
    "if nofilteroverlaps==True:\n",
    "    user_text += '_nofilteroverlaps'\n",
    "\n",
    "    if forcemodamp:\n",
    "        o1 = 1.0\n",
    "        o2 = 0.1\n",
    "        user_text += '_forcemodamp_'+str(o1)+'_'+str(o2)\n",
    "        forcemodamp = [o1, o2]\n",
    "\n",
    "    if forceotfamp:\n",
    "        o1 = 1\n",
    "        o2 = 10\n",
    "        user_text += '_forceotfamp_'+str(o1)+'_'+str(o2)\n",
    "        forceotfamp = [o1, o2]\n",
    "    \n",
    "    base_kwargs.update(dict(nofilteroverlaps=nofilteroverlaps, gammaApo=gammaApo, suppressR=suppressR, wiener=wiener))   # default Full frame Recon. parameters    \n",
    "    if forcemodamp:\n",
    "        base_kwargs.update(dict(forcemodamp=forcemodamp))   # default Full frame Recon. parameters    \n",
    "    elif forceotfamp:\n",
    "        base_kwargs.update(dict(otfamp=forceotfamp))\n",
    "                \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Full frame Simrecon SIM image reconstruction, recon parameters: \n",
    "\n",
    "Set up full frame processing.  Note that we override gammaApo, supressR and wiener parameters.  Also note the code will not be run right away (just put in a dask queue)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "to_process = []\n",
    "\n",
    "for raw in glob.iglob(home + \"/**/*SIM*.mrc\", recursive = True):\n",
    "    wl, otfs = return_wl_otfs(raw)\n",
    "    for otf in otfs:\n",
    "        if \"proc\" not in raw:\n",
    "            print('Data to process ' +str(raw))\n",
    "            # Test with actually measured OTF\n",
    "            sim_kwargs = dict(                                                                                                            \n",
    "                input_file= raw,\n",
    "                otf_file= otf,\n",
    "                ls= (wl/1000)/2/0.81,)\n",
    "            \n",
    "            sim_kwargs.update(base_kwargs)\n",
    "            OTF_filename = os.path.split(otf)[1].split('.')[0]\n",
    "            print('\\nOTF filename: ' +str(OTF_filename))\n",
    "                \n",
    "            #create processed file output name\n",
    "            sim_kwargs[\"output_file\"] = sim_kwargs[\"input_file\"].replace(\".mrc\", '_proc' + OTF_filename + '_' \n",
    "                                                                         + user_text + \".mrc\")\n",
    "                \n",
    "            if sim_kwargs[\"output_file\"] not in done_already:\n",
    "                print(\"\\n\\nSIM recon Data to save:\" + '\\n' + str(sim_kwargs[\"output_file\"]) + '\\n')\n",
    "                to_process.append(process(sim_kwargs, sim_kwargs[\"output_file\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running cell below shows all files being processed for full frame reconstruction and progress using DASK\n",
    "\n",
    "This cell will start and run the processing.  We use dask to compute our processing queue that was set up in the cell above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with ProgressBar():\n",
    "    print(to_process)\n",
    "    out_names = done_already.update(*dask.compute(to_process))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cell below checks for data already processed using the tiledreconstruction method, cell below that creates list of data to be set to done already, i.e. already processed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for path in glob.glob(home + \"/*/*_tile64_pad32*\"):\n",
    "    done_already.add(path.replace(\"_tile64_pad32\", \"\") + \"__split__\")\n",
    "\n",
    "[path for path in done_already if \"_tile64_pad32\" in path]\n",
    "\n",
    "for raw in glob.iglob(home + \"/**/*SIM*.mrc\", recursive = True):\n",
    "    print(raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(home)\n",
    "print(glob.glob(home + \"/**/*SIM_*.mrc\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cell below runs tiled reconstruction of SIM images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#%%time\n",
    "\n",
    "gammaApo = 0.2\n",
    "suppressR =0.1\n",
    "wiener = 0.001\n",
    "done_already = set()\n",
    "base_kwargs.update(dict(gammaApo=gammaApo, suppressR=suppressR, wiener=wiener)) # default tiling Recon. parameters\n",
    "\n",
    "user_text = 'gApo_'+str(gammaApo)+'_supR_'+str(suppressR)+'_w_'+str(wiener)\n",
    "\n",
    "tile_size = 8\n",
    "tile_overlap =4\n",
    "\n",
    "filter_tiles = True\n",
    "         \n",
    "if filter_tiles:\n",
    "    user_text=user_text+'_filter_tiles_set7'\n",
    "\n",
    "    tile_limits = {}\n",
    "   \n",
    "    tile_limits['spacing_min'] = 0.31\n",
    "    tile_limits['spacing_max'] = 0.33\n",
    "    tile_limits['spacing_default']=0.315\n",
    "    tile_limits['angle_min'] = 1.0\n",
    "    tile_limits['angle_max'] = 2.0\n",
    "    tile_limits['angle_default'] = 1.36\n",
    "    tile_limits['amp1_min'] = 0.9\n",
    "    tile_limits['amp1_max'] = 1.1\n",
    "    tile_limits['amp1_default'] = 1.0\n",
    "    tile_limits['amp2_min'] = 0.9\n",
    "    tile_limits['amp2_max'] = 1.1\n",
    "    tile_limits['amp2_default'] = 1.0\n",
    "else:\n",
    "    tile_limits = None\n",
    "\n",
    "\n",
    "\n",
    "for raw in glob.iglob(home + \"/**/*SIM*.mrc\", recursive = True):\n",
    "    wl, otfs = return_wl_otfs(raw)\n",
    "    print(raw)\n",
    "    \n",
    "    for otf in otfs:\n",
    "        if \"proc\" not in raw:                  #checks for if data was already processed\n",
    "            if \"_tile64_pad32\" not in raw:       #checks for if data was already processed using tiling method\n",
    "                print(\"\\nFile to be processed: \" + str(raw))\n",
    "                # Test with actually measured OTF\n",
    "                sim_kwargs = dict(\n",
    "                    input_file= raw,\n",
    "                    otf_file= otf,\n",
    "                    #ls= (wl/1000)/2/0.81,\n",
    "                    ls = .315\n",
    "                )\n",
    "                sim_kwargs.update(base_kwargs)\n",
    "                \n",
    "                OTF_filename = os.path.split(otf)[1].split('.')[0]\n",
    "                \n",
    "                #create processed file output name\n",
    "                out_name = sim_kwargs[\"output_file\"] = sim_kwargs[\"input_file\"].replace(\".mrc\",'_proc_' + OTF_filename + '_' +\n",
    "                                                                          user_text + \".mrc\")\n",
    "                \n",
    "                # perform reconstruction and output recon image file and text file\n",
    "              \n",
    "                out_name += \"__split__\"\n",
    "                \n",
    "                try:\n",
    "                    if out_name not in done_already:\n",
    "                        #print(sim_kwargs[\"input_file\"])\n",
    "                        sim_output = split_process_recombine(sim_kwargs[\"input_file\"], tile_size, tile_overlap, sim_kwargs, tile_limits=tile_limits)\n",
    "                        # HAD TO EDIT simrecon_utils.py lines 1488 and 1490 and comment out mrc.close() as it was failing.\n",
    "                        with open(sim_output[0].replace(\".mrc\", \".txt\"), \"w\") as myfile:\n",
    "                            myfile.write(str(sim_kwargs))\n",
    "                            myfile.write(\"\\n\" + \"-\" * 80 + \"\\n\")\n",
    "                            myfile.write(\"\\n\".join(sim_output[1]))\n",
    "\n",
    "                    done_already.add(out_name)\n",
    "                    for path in glob.glob(home + \"/*/*_tile64_pad32*\"):\n",
    "                        done_already.add(path.replace(\"_tile64_pad32\", \"\") + \"__split__\")\n",
    "                except:\n",
    "                    print('Error processing ' + str(raw))\n",
    "                    continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### from simrecon_utils import process_txt_output, plot_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dst = \"Tiled Parameters/\"\n",
    "try:\n",
    "    os.mkdir(dst)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "for raw in glob.iglob(home + \"/*/*SIM*tile*.txt\"):\n",
    "    with open(raw) as f:\n",
    "        fig, axs = plot_params(process_txt_output(\"\".join(f.readlines())))\n",
    "        fig.savefig(dst + os.path.abspath(raw).split(os.path.sep)[-2] + \".png\", dpi=300, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Renaming 3D SIM files for DropBox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for wl in (\"488 nm\", \"532 nm\", \"560 nm\", \"642 nm\"):\n",
    "    curdir = os.path.split(os.path.abspath(os.curdir))[1]\n",
    "    glob_str = \"F:/ORCA_Data/{}/3D SIM Cells/*{}*/*{}.mrc\".format(curdir, \"\", \"{}*SIM*proc*\".format(wl))\n",
    "    for path in sorted(glob.glob(glob_str)):\n",
    "        print(path)\n",
    "        path_head, path_tail = os.path.split(path)\n",
    "        path_head_new, path_tail_new = os.path.split(path_head)\n",
    "        file_root = path_tail_new.split(\"_\")[0]+' '+path_tail_new.split(\"_\")[1]\n",
    "\n",
    "        OTF = path_tail.split('_OTF')[-1]\n",
    "        proc = OTF.split('_proc')[-1]\n",
    "        if proc == '.mrc':\n",
    "            OTF = proc = OTF.split('_proc')[0] + '.mrc'\n",
    "        new_path = os.path.join(path_head_new, file_root + ' wl'+wl.split(' ')[0]+' proc_with_OTF' + OTF)\n",
    "        print(new_path)\n",
    "        print('')\n",
    "        \n",
    "        shutil.copyfile(path,new_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "simrecon_python_373",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
